{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SentencePiece in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "# python 3.10.11\n",
    "!pip install SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (4.29.2)\n",
      "Requirement already satisfied: pandas in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: sumy in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: torch in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: requests in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: docopt<0.7,>=0.6.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from sumy) (0.6.2)\n",
      "Requirement already satisfied: breadability>=0.1.20 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from sumy) (0.1.20)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from sumy) (22.3.5)\n",
      "Requirement already satisfied: nltk>=3.0.2 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from sumy) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (4.6.2)\n",
      "Requirement already satisfied: sympy in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
      "Requirement already satisfied: wheel in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.5)\n",
      "Requirement already satisfied: chardet in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from breadability>=0.1.20->sumy) (5.1.0)\n",
      "Requirement already satisfied: lxml>=2.0 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from breadability>=0.1.20->sumy) (4.9.2)\n",
      "Requirement already satisfied: fsspec in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: click in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from nltk>=3.0.2->sumy) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from requests->transformers) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers pandas sumy torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda env export > sumy_transformer.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nikivene/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/nikivene/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# @title Предварительная чистка датасета\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "def cleaning_text(text):\n",
    "#     text = text.lower() # Convert to lowercase\n",
    "    text = text.strip()\n",
    "    text = re.sub('<[^>]+>', '',text ,flags = re.DOTALL)\n",
    "    text = re.sub(r\"\\n\", \". \", text)  # Replace ( · ) \n",
    "    text = re.sub(r\"\\s·\", \". \", text)  # Replace ( · )\n",
    "    text = re.sub(r\"\\W\\W\\W\", \". \", text)  # Replace ( · )\n",
    "    text = re.sub(r\"\\W\\W\", \". \", text)  # Replace ( · ) \n",
    "    text = re.sub(\"/[^\\.\\,\\-\\_\\'\\\"\\@\\?\\!\\:\\$ a-zA-Z0-9А-Яа-я()]/u\" ,\"\", text)\n",
    "    text = re.sub('\\s\\W', ' ', text)\n",
    "    text = re.sub('Требования.', '', text)\n",
    "    text = re.sub('Обязанности.', '', text)\n",
    "    text = re.sub('\\W,\\s', '', text) # (Любая не-буква, не-цифра и не подчёркивание) (Любой пробельный символ)\n",
    "    text = re.sub('\\s+', ' ', text) # Любой пробельный символ\n",
    "#     text = ' '.join([i for i in text.split() if i not in stop_words]) # Remove stop_words\n",
    "    text = re.sub(\"nbsp\", \"\", text)\n",
    "    text = re.sub('\\W\\s\\W', '.', text)\n",
    "    text = re.sub('{', '', text)\n",
    "    text = re.sub('}', '', text)\n",
    "#     print(\"::::: Text_Cleaned :::::\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# text = recleaning_text(text_1)\n",
    "# print(text)\n",
    "# print(len(text))\n",
    "# print(cleaning_text(text_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Реализация через `sumy`\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def sumy_LexRank(text, sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"russian\"))\n",
    "    stemmer = Stemmer(\"russian\")    \n",
    "    summarizerLexRank = LexRankSummarizer(stemmer)\n",
    "    summary = ''\n",
    "    for sentenceLexRank in summarizerLexRank(parser.document, sentences_count=sentences):\n",
    "        summary+=' ' + str(sentenceLexRank)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def sumy_Luhn(text, sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"russian\"))\n",
    "    stemmer = Stemmer(\"russian\")\n",
    "    summarizerLuhn = LuhnSummarizer(stemmer)\n",
    "    summary = ''\n",
    "    for sentenceLuhn in summarizerLuhn(parser.document, sentences_count=sentences):\n",
    "        summary+=' ' + str(sentenceLuhn)\n",
    "    return summary\n",
    "\n",
    "def sumy_LSA(text, sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"russian\"))\n",
    "    stemmer = Stemmer(\"russian\")\n",
    "    summarizerLSA = LsaSummarizer(stemmer)\n",
    "    summary = ''\n",
    "    for sentenceLSA in summarizerLSA(parser.document, sentences_count=sentences):\n",
    "        summary+=' ' + str(sentenceLSA)\n",
    "    return summary\n",
    "\n",
    "def sumy_TextRank(text, sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"russian\"))\n",
    "    stemmer = Stemmer(\"russian\")\n",
    "    summarizerTR = TextRankSummarizer(stemmer)\n",
    "    summary = ''\n",
    "    for sentenceTextRank in summarizerTR(parser.document, sentences_count=sentences):\n",
    "        summary+=' ' + str(sentenceTextRank)\n",
    "    return summary\n",
    "\n",
    "def sumy_KLdiv(text, sentences=3):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"russian\"))\n",
    "    stemmer = Stemmer(\"russian\")\n",
    "    summarizerKL = KLSummarizer(stemmer)\n",
    "    summary = ''\n",
    "    for sentenceKL in summarizerKL(parser.document, sentences_count=sentences):\n",
    "        summary+=' ' + str(sentenceKL)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization_pipline_sumy_LexRank(text):\n",
    "    text = cleaning_text(text)\n",
    "    text = sumy_LexRank(text, sentences=3)\n",
    "    return text\n",
    "\n",
    "def summarization_pipline_sumy_Luhn(text):\n",
    "    text = cleaning_text(text)\n",
    "    text = sumy_Luhn(text, sentences=3)\n",
    "    return text\n",
    "\n",
    "def summarization_pipline_sumy_LSA(text):\n",
    "    text = cleaning_text(text)\n",
    "    text = sumy_LSA(text, sentences=3)\n",
    "    return text\n",
    "\n",
    "def summarization_pipline_sumy_TextRank(text):\n",
    "    text = cleaning_text(text)\n",
    "    text = sumy_TextRank(text, sentences=3)\n",
    "    return text\n",
    "\n",
    "def summarization_pipline_sumy_KLdiv(text):\n",
    "    text = cleaning_text(text)\n",
    "    text = sumy_KLdiv(text, sentences=3)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Обязанности:    \\r\\n \\r\\n   Приёмка, расценк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Обязанности:  \\r\\n Приемка и контроль качеств...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Кадастровый инженер\\r\\n\\r\\nВ связи с расширени...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ольга Гринюк (Olga Grinyuk) - российская марка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Обязанности:    \\r\\nПошив чехлов на мягкую м...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          full_text\n",
       "0           0    Обязанности:    \\r\\n \\r\\n   Приёмка, расценк...\n",
       "1           1   Обязанности:  \\r\\n Приемка и контроль качеств...\n",
       "2           2  Кадастровый инженер\\r\\n\\r\\nВ связи с расширени...\n",
       "3           3  Ольга Гринюк (Olga Grinyuk) - российская марка...\n",
       "4           4    Обязанности:    \\r\\nПошив чехлов на мягкую м..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_to_summary = pd.read_csv('./data/df_to_summary.csv')\n",
    "\n",
    "df_to_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>full_text</th>\n",
       "      <th>sumy_LSA</th>\n",
       "      <th>sumy_TextRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Обязанности:    \\r\\n \\r\\n   Приёмка, расценк...</td>\n",
       "      <td>выкладка товара. поддержание чистоты. Смена с...</td>\n",
       "      <td>выкладка товара. поддержание чистоты. Смена с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Обязанности:  \\r\\n Приемка и контроль качеств...</td>\n",
       "      <td>Приемка и контроль качества сырья. участие в ...</td>\n",
       "      <td>Приемка и контроль качества сырья. участие в ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Кадастровый инженер\\r\\n\\r\\nВ связи с расширени...</td>\n",
       "      <td>В связи с расширением объема услуг. в агентст...</td>\n",
       "      <td>в агентство недвижимости требуется кадастровы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ольга Гринюк (Olga Grinyuk) - российская марка...</td>\n",
       "      <td>Вот уже 15 лет все платья создаются в Ростове...</td>\n",
       "      <td>Выпускается 12 коллекций в год. до 80 различн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Обязанности:    \\r\\nПошив чехлов на мягкую м...</td>\n",
       "      <td>Пошив чехлов на мягкую мебель. можно обучение...</td>\n",
       "      <td>Пошив чехлов на мягкую мебель. можно обучение...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          full_text   \n",
       "0           0    Обязанности:    \\r\\n \\r\\n   Приёмка, расценк...  \\\n",
       "1           1   Обязанности:  \\r\\n Приемка и контроль качеств...   \n",
       "2           2  Кадастровый инженер\\r\\n\\r\\nВ связи с расширени...   \n",
       "3           3  Ольга Гринюк (Olga Grinyuk) - российская марка...   \n",
       "4           4    Обязанности:    \\r\\nПошив чехлов на мягкую м...   \n",
       "\n",
       "                                            sumy_LSA   \n",
       "0   выкладка товара. поддержание чистоты. Смена с...  \\\n",
       "1   Приемка и контроль качества сырья. участие в ...   \n",
       "2   В связи с расширением объема услуг. в агентст...   \n",
       "3   Вот уже 15 лет все платья создаются в Ростове...   \n",
       "4   Пошив чехлов на мягкую мебель. можно обучение...   \n",
       "\n",
       "                                       sumy_TextRank  \n",
       "0   выкладка товара. поддержание чистоты. Смена с...  \n",
       "1   Приемка и контроль качества сырья. участие в ...  \n",
       "2   в агентство недвижимости требуется кадастровы...  \n",
       "3   Выпускается 12 коллекций в год. до 80 различн...  \n",
       "4   Пошив чехлов на мягкую мебель. можно обучение...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_summary['sumy_LSA'] = df_to_summary['full_text'].apply(summarization_pipline_sumy_LSA)\n",
    "df_to_summary['sumy_TextRank'] = df_to_summary['full_text'].apply(summarization_pipline_sumy_TextRank)\n",
    "df_extract = df_to_summary\n",
    "df_to_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikivene/ITMO_Projects/Dataset_for_SFT/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "MODEL_NAME = \"cointegrated/rut5-base-paraphraser\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "# model.cuda();\n",
    "# model.eval();\n",
    "\n",
    "def paraphrase(text, beams=3, grams=3, do_sample=False):\n",
    "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
    "    out = model.generate(**x, encoder_no_repeat_ngram_size=grams, num_beams=beams,\n",
    "                         max_length=52, min_length=40,  do_sample=do_sample,\n",
    "                         top_p=0.9)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_paraphrase(text):\n",
    "    if type(text) == str:\n",
    "        if 200 < len(text):\n",
    "            return paraphrase(text)\n",
    "            \n",
    "    return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extract['rut5-base-paraphraser(LSA)'] = df_extract['sumy_LSA'].apply(min_max_paraphrase)\n",
    "df_extract['rut5-base-paraphraser(TextRank)'] = df_extract['sumy_TextRank'].apply(min_max_paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rut5-base-paraphraser(LSA)</th>\n",
       "      <th>rut5-base-paraphraser(TextRank)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Готовы к развитию и совершенствованию своей пр...</td>\n",
       "      <td>Наш мастер зарабатывает от 3000 до 9000 рублей...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Разработчик и производитель специальных агрега...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Международная сети магазинов всех семей с боль...</td>\n",
       "      <td>В международной сети магазинов всех семей с ши...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Проектирование и изготовление готовых изделий ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           rut5-base-paraphraser(LSA)   \n",
       "0                                                 NaN  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5   Готовы к развитию и совершенствованию своей пр...   \n",
       "6                                                 NaN   \n",
       "7   Разработчик и производитель специальных агрега...   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15  Международная сети магазинов всех семей с боль...   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25                                                NaN   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "\n",
       "                      rut5-base-paraphraser(TextRank)  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5   Наш мастер зарабатывает от 3000 до 9000 рублей...  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15  В международной сети магазинов всех семей с ши...  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  \n",
       "20                                                NaN  \n",
       "21  Проектирование и изготовление готовых изделий ...  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abstract = df_extract[['rut5-base-paraphraser(LSA)','rut5-base-paraphraser(TextRank)']]\n",
    "\n",
    "df_abstract.to_csv('./data/df_abstract.csv')\n",
    "df_abstract.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extract.to_csv('summarization_final_100.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
