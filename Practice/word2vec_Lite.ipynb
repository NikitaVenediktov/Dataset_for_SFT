{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec model\n",
    "\n",
    "Write a program that trains Word2Vec model. Do not use print() instructions in your code, otherwise test procedure will not succeed; the message \"Wrong Answer\" indicates answer format is incorrect (print() in the code, missing words in the dictionary, etc.). The message \"Embeddings are not good enough\" means you're on the right track and you should focus on the model improvement. In this version of the assignment the checks on the embeddings are easier.\n",
    "\n",
    "You may think of the input string as being pre-processed with the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import string\n",
    "\n",
    "def clean(inp: str) -> str:\n",
    "\n",
    "    inp = inp.translate(str.maketrans(string.punctuation, \" \"*len(string.punctuation)))\n",
    "\n",
    "    inp = re.sub(r'\\s+', ' ', inp.lower())\n",
    "\n",
    "    return inp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I.e. given the input \"Your string!\" the output will be \"your string \".\n",
    "\n",
    "Input: data (string) - cleaned documents without punctuation in one line\n",
    "Output: w2v_dict (dict: key (string) - a word from vocabulary, value (numpy array) - the word's embedding)\n",
    "\n",
    "Time limit: 25 seconds\n",
    "Memory limit: 128 MB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def train(data: str):\n",
    "    \"\"\"\n",
    "    return: w2v_dict: dict\n",
    "            - key: string (word)\n",
    "            - value: np.array (embedding)\n",
    "    \"\"\"\n",
    "    words = data.split()\n",
    "    vocab = set(words)\n",
    "    word2idx = {w: np.array(idx) for (idx, w) in enumerate(vocab)}\n",
    "    return word2idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /Users/nikitav/Library/Python/3.9/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/nikitav/Library/Python/3.9/lib/python/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /Users/nikitav/Library/Python/3.9/lib/python/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nikitav/Library/Python/3.9/lib/python/site-packages (from nltk) (2023.3.23)\n",
      "Requirement already satisfied: click in /Users/nikitav/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "namespace(target=97, context=110, label=1)\n",
      "namespace(target=97, context=[123, 35, 19, 153, 147, 61], label=0)\n"
     ]
    }
   ],
   "source": [
    "# мое решение \n",
    "\n",
    "\n",
    "text = '''As the eight strange beings applauded, one of them even cupping a hand over her lipsticked mouth to cheer, Joel tried to grasp what was happening. The nine of them sat in a fire rimmed cavern around a conference table shaped from warm volcanic rock. A chandelier of human bones dangled from the cavern’s ceiling, and it rattled around at random like wind chimes. A massive goat-man with reddish-black skin and wicked horns on his head towered above the seven others, who flanked him to either side. They looked like pure stereotype. A fat slob with sixteen chins, a used car saleman looking guy with gold and silver jewelry all over him, a sultry dominatrix in skin tight leather. On the other side a disheveled looking college drop out, a pretty boy staring in a mirror, a bald, muscular dude who looked like someone’s pissed off step-dad and a sour faced woman glancing jealously around the room. Just where the hell was he? Joel concentrated on his last memory. He remembered highlighting pages as his private jet, “The Holy Gust,” flew over the sapphire waters of the Bahamas. He had been reviewing his sermon for Sunday – dotting the I’s and crossing the crosses, a little god humor there, praise him – and the pilot’s voice had crackled over the intercom about turbulence. Kimberly, his personal assistant, had taken his plow out of her mouth and put on her seat belt. The plane had shook and then'''.lower()\n",
    "\n",
    "words = text.split()\n",
    "vocab = set(words)\n",
    "word2idx = {w: idx for (idx, w) in enumerate(tokenized_corpus)}\n",
    "idx2word = {idx: w for (idx, w) in enumerate(tokenized_corpus)}\n",
    "\n",
    "tokenized_corpus = vocab\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "def generate_negative_samples(target_index, index_range, k):\n",
    "    '''\n",
    "    index_range: ranges of index to select from\n",
    "    '''\n",
    "    random_index = random.sample(index_range, 6) # количество конкретное (почему 6?)\n",
    "    \n",
    "    return  SimpleNamespace(\n",
    "                target=word2idx[words[target_index]],\n",
    "                context=[word2idx[word] for word in [words[index] for index in random_index]],\n",
    "                label=0\n",
    "            )\n",
    "\n",
    "def text_to_train(words, context_window=2, k=6):\n",
    "    '''\n",
    "    Make training data from words.\n",
    "    \n",
    "    For 1 positive sample, generate `k` negative samples\n",
    "    '''\n",
    "    pos = []\n",
    "    neg = []\n",
    "    context_range = range(-context_window, context_window+1)\n",
    "    for current_index in range(context_window, len(words) - context_window ) :\n",
    "        #Positive Samples\n",
    "        for relative_index in context_range:\n",
    "            if current_index + relative_index != current_index:\n",
    "                pos.append(SimpleNamespace(\n",
    "                    target=word2idx[words[current_index]],\n",
    "                    context=word2idx[words[current_index+relative_index]],\n",
    "                    label=1\n",
    "                ))\n",
    "        #Negative Samples\n",
    "        for _ in context_range:\n",
    "            \n",
    "            rand = random.random()\n",
    "            \n",
    "            lhs_index_range = None\n",
    "            rhs_index_range = None\n",
    "            # select from lhs of target\n",
    "            if  (current_index - context_window - 2*k) > 0:\n",
    "                #This also accounts for the fact that there should be ample samples on the LHS to select from\n",
    "                lhs_index_range = range(0, current_index - context_window)\n",
    "                \n",
    "            if (current_index + context_window + 2*k ) < len(words):\n",
    "                # If random value is >= 0.5 or there are not enough samples on the LHS\n",
    "                rhs_index_range = range(current_index + context_window, len(words))\n",
    "            \n",
    "            if lhs_index_range and rhs_index_range:\n",
    "                index_range = random.choice([lhs_index_range, rhs_index_range])\n",
    "            elif lhs_index_range:\n",
    "                index_range = lhs_index_range\n",
    "            else:\n",
    "                index_range = rhs_index_range\n",
    "\n",
    "            neg.append(\n",
    "                    generate_negative_samples(\n",
    "                        current_index,\n",
    "                        index_range=index_range,\n",
    "                        k=k\n",
    "                    )\n",
    "                )\n",
    "    return pos, neg\n",
    "\n",
    "pos_data, neg_data = text_to_train(words)\n",
    "\n",
    "print(pos_data[0])\n",
    "print(neg_data[0])\n",
    "# def train(data: str):\n",
    "#     \"\"\"\n",
    "#     return: w2v_dict: dict\n",
    "#             - key: string (word)\n",
    "#             - value: np.array (embedding)\n",
    "#     \"\"\"\n",
    "\n",
    "#     return {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
